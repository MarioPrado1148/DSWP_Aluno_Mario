{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_catboost_20201130b_notebookZenilson.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioPrado1148/DSWP_Aluno_Mario/blob/MarioPrado1148-Notebooks/Kaggle_catboost_20201130b_notebookZenilson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFJ3zOQFPpqs"
      },
      "source": [
        "## 1. Instalação do CATBOOST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkrLBqU_4JY1",
        "outputId": "9e6cf969-7217-4e34-8163-468b9b664250"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
            "\u001b[K     |████████████████████████████████| 66.3MB 83kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sscsjFpPuKh"
      },
      "source": [
        "##2. Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OIAnorJ5Ex_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix # para plotar a confusion matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV # para otimizar os hiperparâmetros dos modelos preditivos\n",
        "from sklearn.model_selection import cross_val_score # Para o CV (Cross-Validation)\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2UHV7VHPz9k"
      },
      "source": [
        "## 3. Carregando os dataframes iniciais com os dados de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNXKrBUg5qd-"
      },
      "source": [
        "df_treino = pd.read_csv(\"train.csv\")\n",
        "df_teste = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf44Mi11P7XQ"
      },
      "source": [
        "## 4. Classe para tratamento dos dados do DataFrame.   A intenção ao utilizar uma classe pra isso foi a possibilidade de ir adicionando métodos que retornem diferentes \"versões\" do dataframe, com diferentes tratamentos de features...e ir testando/mantendo aquelas que tenham mais sucesso.\n",
        "### Observações:\n",
        "1. O dataframe \"original\" é passado como parâmetro na criação do objeto.   Ao instanciar o objeto alguns tratamentos iniciais, sugeridos pelo Mario, são aplicados (ex: renomear colunas, missing values, conversão de tipo, etc.) \n",
        "2. Após a criação, posso utilizar algo como objeto.getDataFramexxxxxx() para obter o dataframe com o tratamento específico definido no respectivo método."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDt-BP2956_k"
      },
      "source": [
        "class Trata_DataFrame():\n",
        "    def __init__(self,df):\n",
        "      self.df = df\n",
        "      self.renomeia_colunas()\n",
        "      self.trata_CobrancaTotal()\n",
        "      self.trata_MesesNaCompanhia()\n",
        "      self.trata_MetodoPagamento()\n",
        "      self.trata_TemDependentes()\n",
        "      self.trata_Idoso()\n",
        "\n",
        "    def renomeia_colunas(self):\n",
        "       self.df.rename(columns = {'id':'id',\n",
        "                                'gender':'genero',\n",
        "                                'SeniorCitizen':'Idoso',\n",
        "                                'Partner':'TemParceiro',\n",
        "                                'Dependents':'TemDependentes',\n",
        "                                'tenure':'MesesNaCompanhia',\n",
        "                                'PhoneService':'TemTelefone',\n",
        "                                'MultipleLines':'MaisLinhas',\n",
        "                                'InternetService':'TemInternet',\n",
        "                                'OnlineSecurity':'ServicoSegurancaOnline',\n",
        "                                'OnlineBackup':'ServicoBackupOnline',\n",
        "                                'DeviceProtection':'ServicoProtecaoOnline',\n",
        "                                'TechSupport':'ServicoSuporteOnline',\n",
        "                                'StreamingTV':'ServicoTV',\n",
        "                                'StreamingMovies':'ServicoPctFilmes',\n",
        "                                'Contract':'Contrato',\n",
        "                                'PaperlessBilling':'ContaOnline',\n",
        "                                'PaymentMethod':'MetodoPagamento',\n",
        "                                'MonthlyCharges':'CobrancaMensal',\n",
        "                                'TotalCharges':'CobrancaTotal',\n",
        "                                'Churn':'Churn'}, inplace=True)   \n",
        "\n",
        "    def trata_MetodoPagamento(self):\n",
        "        ''' atribui uma string ('MISS') aos valores missing da coluna.'''\n",
        "        self.df.loc[self.df[\"MetodoPagamento\"].isna(),\"MetodoPagamento\"] = \"MISS\"\n",
        "    def trata_TemDependentes(self):\n",
        "        ''' atribui o valor Yes ao campo TemDependentes caso o cliente possua mais de uma linha, e 'No' caso não possua'''\n",
        "        self.df.loc[self.df[\"TemDependentes\"].isna(),\"TemDependentes\"] = \"MISS\"\n",
        "        self.df.loc[(self.df[\"MaisLinhas\"] == 'No') & (self.df[\"TemDependentes\"] == 'MISS'), \"TemDependentes\"] = \"No\"\n",
        "        self.df.loc[(self.df[\"MaisLinhas\"] == 'Yes') & (self.df[\"TemDependentes\"] == 'MISS'), \"TemDependentes\"] = \"Yes\"\n",
        "\n",
        "    def trata_CobrancaTotal(self):\n",
        "        '''  converte os valores para número...Em seguida substitui Nan por MesesNaCompanhia * CobrancaMensal '''\n",
        "        self.df['CobrancaTotal'] = pd.to_numeric(self.df['CobrancaTotal'], errors='coerce')\n",
        "        self.df.loc[np.isnan(self.df[\"CobrancaTotal\"]),\"CobrancaTotal\"] = self.df[\"MesesNaCompanhia\"] * self.df[\"CobrancaMensal\"]\n",
        "    \n",
        "    def trata_Idoso(self):\n",
        "      self.df[\"Idoso\"] = self.df[\"Idoso\"].astype('str')\n",
        "\n",
        "    def trata_MesesNaCompanhia(self):\n",
        "        ''' recalcula a qtde de meses dos missing values dividindo o valor total pelo valor mensal '''   \n",
        "        self.df.loc[np.isnan(self.df[\"MesesNaCompanhia\"]),\"MesesNaCompanhia\"] = round(self.df[\"CobrancaTotal\"] / self.df[\"CobrancaMensal\"],0)\n",
        "        self.df[\"MesesNaCompanhia\"] = self.df[\"MesesNaCompanhia\"].astype(\"float\")\n",
        "\n",
        "    def getDataFrameDefault(self):\n",
        "        ''' retorna o dataframe apenas com os ajustes iniciais \"'''\n",
        "        return self.df  \n",
        "\n",
        "    def getDataFrameMelhoresFeatures(self): #dataframe utilizado na primeira submissão do kaggle a atingir 0.80397\n",
        "        ''' Utiliza como base o dataframe com os ajustes iniciais e realiza nele as seguintes operações:\n",
        "            - adiciona a QtdeServicosAdicionaisInternet, onde são totalizadas 4 colunas\n",
        "            - Deixa as colunas \"ServicoTV\" \"ServicoPctFilmes\" apenas com os valores Yes e No (No phone service é substituido por No)\n",
        "            - Exclusão das colunas 'genero' e 'Temparceiro'....A ausência das colunas melhorou a acurácia no treino em vários modelos que testei, por isso resolvi excluí-las\n",
        "            - Exclusão das quatro colunas de serviços adicionais de internet, que foram totalizadas na nova coluna criada.\n",
        "            - Exclusão da coluna \"TemTelefone\".   Entendo que a informação do campo \"MaisLinhas\" ja é suficiente.\n",
        "            - chama o método que adiciona a coluna \"anos na companhia\".\n",
        "        '''                  \n",
        "        df2 = self.df.copy()\n",
        "        df2[\"QtdeServicosAdicionaisInternet\"] = 0\n",
        "        df2.loc[df2[\"ServicoSegurancaOnline\"] == \"Yes\",\"QtdeServicosAdicionaisInternet\"] = df2[\"QtdeServicosAdicionaisInternet\"] + 1\n",
        "        df2.loc[df2[\"ServicoBackupOnline\"] == \"Yes\",\"QtdeServicosAdicionaisInternet\"] =  df2[\"QtdeServicosAdicionaisInternet\"] + 1\n",
        "        df2.loc[df2[\"ServicoProtecaoOnline\"] == \"Yes\",\"QtdeServicosAdicionaisInternet\"] =  df2[\"QtdeServicosAdicionaisInternet\"] + 1\n",
        "        df2.loc[df2[\"ServicoSuporteOnline\"] == \"Yes\",\"QtdeServicosAdicionaisInternet\"] = df2[\"QtdeServicosAdicionaisInternet\"] + 1\n",
        "        df2.loc[df2[\"ServicoTV\"] != \"Yes\",\"ServicoTV\"] =  \"No\"\n",
        "        df2.loc[df2[\"ServicoPctFilmes\"] != \"Yes\",\"ServicoPctFilmes\"] = \"No\"\n",
        "        df2[\"QtdeServicosAdicionaisInternet\"] = df2[\"QtdeServicosAdicionaisInternet\"].astype('int64')\n",
        "        df2.drop(columns=[\"genero\",\"TemParceiro\",\"TemTelefone\",\"ServicoSegurancaOnline\",\"ServicoBackupOnline\",\"ServicoProtecaoOnline\",\"ServicoSuporteOnline\" ],inplace=True)\n",
        "        return df2   \n",
        "\n",
        "    def getDataFrameMelhoresFeatures2(self): # também atigiu, em três arquivos diferentes, a nota 0.80397....tb gerou 0.802... e 0.801...\n",
        "        ''' Utilizando o dataframe retornado pelo método getDataFrameMelhoresFeatures(), acrescenta a coluna \"AnosNaCompanhia\", onde os valores são agrupados por faixa '''\n",
        "        df2 = self.getDataFrameMelhoresFeatures() \n",
        "        df2[\"AnosNaCompanhia\"] = \"\"\n",
        "        df2.loc[df2[\"MesesNaCompanhia\"] <= 12,\"AnosNaCompanhia\"] = \"0 a 1\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 12) & (df2[\"MesesNaCompanhia\"] <= 24),\"AnosNaCompanhia\"] = \"1 a 2\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 24) & (df2[\"MesesNaCompanhia\"] <= 36),\"AnosNaCompanhia\"] = \"2 a 3\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 36) & (df2[\"MesesNaCompanhia\"] <= 48),\"AnosNaCompanhia\"] = \"3 a 4\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 48) & (df2[\"MesesNaCompanhia\"] <= 60),\"AnosNaCompanhia\"] = \"4 a 5\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 60) & (df2[\"MesesNaCompanhia\"] <= 72),\"AnosNaCompanhia\"] = \"5 a 6\"\n",
        "        df2.loc[(df2[\"MesesNaCompanhia\"] > 72),\"AnosNaCompanhia\"] = \"6 a 7\"  \n",
        "        df2.drop(columns=[\"MesesNaCompanhia\"])\n",
        "        return df2        \n",
        "\n",
        "    def getDataFramePrecoMedio(self): # resultados ruins...\n",
        "        ''' retorna o dataframe default, adicionando duas novas colunas (qtdeServicos e vlrMedioPorServico), e igualando \"No\" e \"No internet service\" das colunas relativas a serviços online '''\n",
        "        df2 = self.df.copy()\n",
        "        df2[\"QtdeServicos\"] = 0\n",
        "        df2.loc[df2[\"TemTelefone\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"TemInternet\"] != \"No\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoTV\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoSegurancaOnline\"] == \"Yes\",\"QtdeServicos\"] = df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoBackupOnline\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoProtecaoOnline\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoPctFilmes\"] == \"Yes\",\"QtdeServicos\"] = df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoSuporteOnline\"] == \"Yes\",\"QtdeServicos\"] = df2[\"QtdeServicos\"] + 1\n",
        "\n",
        "        df2.loc[df2[\"ServicoTV\"] != \"Yes\",\"ServicoTV\"] =  \"No\"\n",
        "        df2.loc[df2[\"ServicoSegurancaOnline\"] != \"Yes\",\"ServicoSegurancaOnline\"] = \"No\"\n",
        "        df2.loc[df2[\"ServicoBackupOnline\"] != \"Yes\",\"ServicoBackupOnline\"] =  \"No\"\n",
        "        df2.loc[df2[\"ServicoProtecaoOnline\"] != \"Yes\",\"ServicoProtecaoOnline\"] = \"No\"\n",
        "        df2.loc[df2[\"ServicoPctFilmes\"] != \"Yes\",\"ServicoPctFilmes\"] = \"No\"\n",
        "        df2.loc[df2[\"ServicoSuporteOnline\"] != \"Yes\",\"ServicoSuporteOnline\"] = \"No\"\n",
        "        df2[\"QtdeServicos\"] = df2[\"QtdeServicos\"].astype('float')\n",
        "        df2.drop(columns=[\"TemParceiro\"],inplace=True)\n",
        "        #df2[\"vlrMedioPorServico\"] = df2[\"CobrancaMensal\"] / df2[\"QtdeServicos\"]\n",
        "\n",
        "        return df2  \n",
        "\n",
        "    def getDataFrameServAdicionais(self): # não melhorou resultados no treino...\n",
        "        ''' Utilizando como base o dataframe \"padrão\" (com os ajustes iniciais), retorna dataframe com nova coluna apenas com o indicativo pra saber se há serviços adicionais de internet '''\n",
        "        df2 = self.df.copy()\n",
        "        df2[\"ServicosAdicionaisInternet\"] = \"No\"\n",
        "        df2.loc[df2[\"ServicoSegurancaOnline\"] == \"Yes\",\"ServicosAdicionaisInternet\"] = \"Yes\"\n",
        "        df2.loc[df2[\"ServicoBackupOnline\"] == \"Yes\",\"ServicosAdicionaisInternet\"] =  \"Yes\"\n",
        "        df2.loc[df2[\"ServicoProtecaoOnline\"] == \"Yes\",\"ServicosAdicionaisInternet\"] =  \"Yes\"\n",
        "        df2.loc[df2[\"ServicoPctFilmes\"] == \"Yes\",\"ServicosAdicionaisInternet\"] = \"Yes\"\n",
        "        df2.loc[df2[\"ServicoSuporteOnline\"] == \"Yes\",\"ServicosAdicionaisInternet\"] = \"Yes\"\n",
        "        df2.loc[df2[\"ServicoTV\"] == \"Yes\",\"ServicosAdicionaisInternet\"] = \"Yes\"\n",
        "        #df2.drop(columns = [ \"ServicoSegurancaOnline\",\"ServicoBackupOnline\",\"ServicoSuporteOnline\",\"ServicoProtecaoOnline\",\"ServicoPctFilmes\",\"ServicoTV\"],inplace=True)\n",
        "        df2.drop(columns = [\"TemParceiro\", \"TemDependentes\", \"ServicoSegurancaOnline\",\"ServicoBackupOnline\",\"ServicoSuporteOnline\",\"ServicoProtecaoOnline\",\"ServicoPctFilmes\",\"ServicoTV\"],inplace=True)\n",
        "        return df2\n",
        "\n",
        "    def getDataFrameQtdeServicos2(self):  # não melhorou resultados no treino...\n",
        "        df2 = self.df.copy()\n",
        "        df2[\"QtdeServicos\"] = 0\n",
        "        df2[\"QtdeServicosAdicionais\"] = 0\n",
        "        df2.loc[df2[\"TemTelefone\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"TemInternet\"] != \"No\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoTV\"] == \"Yes\",\"QtdeServicos\"] =  df2[\"QtdeServicos\"] + 1\n",
        "        df2.loc[df2[\"ServicoSegurancaOnline\"] == \"Yes\",\"QtdeServicosAdicionais\"] =  df2[\"QtdeServicosAdicionais\"] + 1\n",
        "        df2.loc[df2[\"ServicoBackupOnline\"] == \"Yes\",\"QtdeServicosAdicionais\"] =  df2[\"QtdeServicosAdicionais\"] + 1\n",
        "        df2.loc[df2[\"ServicoProtecaoOnline\"] == \"Yes\",\"QtdeServicosAdicionais\"] =  df2[\"QtdeServicosAdicionais\"] + 1\n",
        "        df2.loc[df2[\"ServicoPctFilmes\"] == \"Yes\",\"QtdeServicosAdicionais\"] =  df2[\"QtdeServicosAdicionais\"] + 1\n",
        "        df2.loc[df2[\"ServicoSuporteOnline\"] == \"Yes\",\"QtdeServicosAdicionais\"] =  df2[\"QtdeServicosAdicionais\"] + 1\n",
        "        df2[\"QtdeServicos\"] = df2[\"QtdeServicos\"].astype('float')\n",
        "        df2[\"QtdeServicosAdicionais\"] = df2[\"QtdeServicosAdicionais\"].astype('float')\n",
        "        df2.drop(columns = [\"TemTelefone\",\"TemInternet\",\"ServicoTV\",\"ServicoSegurancaOnline\",\"ServicoBackupOnline\",\"ServicoSuporteOnline\",\"ServicoProtecaoOnline\",\"ServicoPctFilmes\"],inplace=True)\n",
        "        return df2          \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaxFopw2RThP"
      },
      "source": [
        "## 5. Criação dos objetos \"Trata_DataFrame\" para os dataframes de Teste e de Treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuD7TrKc6CbS"
      },
      "source": [
        "otdf_Treino = Trata_DataFrame(df_treino)\n",
        "otdf_Teste = Trata_DataFrame(df_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvtpUmxsQO08"
      },
      "source": [
        "## 6. Função para treino/teste\n",
        "### Parametros da função:\n",
        "  * dfTreino -> dataframe para treino do modelo.\n",
        "  * dfTeste -> dataframe de teste.  Não precisa ser fornecido se gerarArquivo = False\n",
        "  * ts -> tamanho percentual do conjunto de teste (test_size do train_test_split)\n",
        "  * it, lr e depth -> parâmetros 'iterations', learning_rate e depth do CatBoostClassifier\n",
        "  * rs -> seed.  parâmetro random_state para o train_test_split\n",
        "  * gerarArquivo e accMinGerarArquivo -> Caso gerarARquivo = \"True\", vai aplicar o modelo no dataframe de teste e gerar o arquivo de resultado para submeter no kaggle, desde que a acurácia do treino seja superior ao parâmetro accMinGerarArquivo\n",
        "  * mostrarFI -> mostra a importância de cada feature\n",
        "  * retorna a acurácia obtida no treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26hXIXmUBzYV"
      },
      "source": [
        "def cbc_treina_testa(dfTreino=None, dfTeste=None, ts=0.30,it=300, lr=0.03, depth=5, rs= None, gerarArquivo=False, accMinGerarArquivo = 82, mostrarFI=False):\n",
        "   preditoras = dfTreino.copy()\n",
        "   preditoras.drop(columns=[\"Churn\",\"id\"],inplace=True)\n",
        "   target = dfTreino[\"Churn\"]\n",
        "   categorical_features_indices = np.where((preditoras.dtypes != np.float))[0] #considerei todas as features que não são do tipo \"flutuante\" como categóricas\n",
        "   X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(preditoras, target, test_size = ts, random_state = rs)\n",
        "   catb = CatBoostClassifier(iterations = it, learning_rate = lr, depth=depth, silent=True)\n",
        "   catb_tuned = catb.fit(  X_treinamento, y_treinamento, cat_features=categorical_features_indices)\n",
        "   y_pred = catb_tuned.predict(X_teste)\n",
        "   acc_catb = round(accuracy_score(y_teste, y_pred) * 100, 2)\n",
        "   print('ts: {} it: {} lr: {} depth: {} rs: {} -> '.format(ts,it,lr,depth, rs)+'Score do Treino: %' + str(acc_catb))\n",
        "   if (mostrarFI == True):\n",
        "      l_fi = list(zip(X_treinamento.columns, catb_tuned.feature_importances_))\n",
        "      print(l_fi)\n",
        "   if (gerarArquivo == True) and (acc_catb >= accMinGerarArquivo):  \n",
        "      df_id = dfTeste[[\"id\"]]\n",
        "      df_teste3 = dfTeste.drop(columns=[\"id\"])\n",
        "      resposta = catb_tuned.predict(df_teste3)\n",
        "      resposta_df = pd.DataFrame(resposta, columns=['Churn'])\n",
        "      resultado_submissao = pd.concat([df_id, resposta_df],axis=1)\n",
        "      resultado_submissao.head().T\n",
        "      filename = 'novo_submissao_kaggle_catb_fs_ts0{}_it{}_lr{}_depth{}_rs{}_sc{}.csv'.format(round(ts*100,0),it, lr, depth,rs,str(int(acc_catb*100)))\n",
        "      resultado_submissao.to_csv(filename, index=False)   \n",
        "      print(filename)\n",
        "   return acc_catb   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td95qOQq4luZ"
      },
      "source": [
        "## 7. Aqui realizei alguns testes, treinando alguns modelos a partir do dataframe \"Default\", e avaliei a importância das features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea1Zyg7y4lT-",
        "outputId": "912da7ed-be9c-4f23-80c0-a1abfc3bd738"
      },
      "source": [
        "# obtém o dataframe default :\n",
        "\n",
        "df_TreinoDefault = otdf_Treino.getDataFrameDefault()\n",
        "\n",
        "# cria e treina o modelo, apresentando as feature_importances...\n",
        "\n",
        "cbc_treina_testa(dfTreino=df_TreinoDefault, rs = 310, mostrarFI=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.3 it: 300 lr: 0.03 depth: 5 rs: 310 -> Score do Treino: %81.25\n",
            "[('genero', 0.48213235480793815), ('Idoso', 0.9702756992426257), ('TemParceiro', 0.1377586168432712), ('TemDependentes', 1.5860880201226373), ('MesesNaCompanhia', 14.247894902515934), ('TemTelefone', 0.3954919730615556), ('MaisLinhas', 3.1534183846630617), ('TemInternet', 15.772634197805669), ('ServicoSegurancaOnline', 4.925075009667106), ('ServicoBackupOnline', 2.902601332978861), ('ServicoProtecaoOnline', 1.637678694128276), ('ServicoSuporteOnline', 3.9353798260668498), ('ServicoTV', 1.720860772976292), ('ServicoPctFilmes', 2.9263865633661017), ('Contrato', 25.53023233803254), ('ContaOnline', 3.3745372293927227), ('MetodoPagamento', 3.553531907795029), ('CobrancaMensal', 5.618433068556928), ('CobrancaTotal', 7.129589107976612)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtgUDg6R7piw"
      },
      "source": [
        "#### Obs: \n",
        " * gênero (0.48) e TemParceiro (0.13) apresentaram baixa importância, motivo pelo qual resolvi eliminá-las implementando o método getMelhoresFeatures()\n",
        " * TemTelefone tem baixa importância (0.39).   Além disso, entendi que a mesma informação já está sendo representada na features 'MaisLinhas', que apresenta três valores possíveis: Yes, No e No Phone Service....Entendo que quando o catboost criar as colunas dummy a partir desta, a situação de \"TemTelefone já estará representada, motivo pelo qual resolvi eliminá-la.\n",
        " * Além da exclusão das features, fiz algumas outras simulações, e fui mantendo aquelas cujo resultado do treino ia melhorando:\n",
        "  - Em um dos testes, criei uma feature para quantificar todos os serviços contratados, mas não vi melhoria\n",
        "  - Também criei uma feature com o preço médio por serviço, que também não melhorou os resultados.\n",
        "  - Em outro teste, totalizei na feature apenas os 4 serviços adicionais de internet, que acabei mantendo por ter melhorado o treino.\n",
        "\n",
        "  - \n",
        "   aquelas criei uma feature para totalizar a quantidade de serviços, que não deu muito resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pkZY_IR-177"
      },
      "source": [
        "## 8. Recuperação dos dataframes de treino e teste com as features selecionadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vLkkjBm6lki"
      },
      "source": [
        "df_treino_mf2 = otdf_Treino.getDataFrameMelhoresFeatures2()\n",
        "df_teste_mf2 = otdf_Teste.getDataFrameMelhoresFeatures2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi-4vpB5wLKv"
      },
      "source": [
        "Observações:\n",
        "   * O primeiro resultado de 0.80397 na submissão foi obtido utilizando o dataframe retornado por \"getMelhoresFeatures()\n",
        "   * Posteriormente, com a implementação de getMelhoresFeatures2(), consegui repetir o mesmo resultado (0.80397) outras vezes, além de conseguir várias submissões superiores a 0.80."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMHrUz1r_U1H"
      },
      "source": [
        "## 9. Modelos iniciais no catboost\n",
        "* Tentei ajustar alguns parâmetros do catboost (iterations, depth, learning_rate), mas percebi que quando encontrava parâmetros que produziam bons resultados no treino, os resultados do kaggle eram bem diferentes, e se modificasse a \"seed\" utilizada no 'random_state' para fazer o split do treino a acurácia mudava completamente, o que tornava necessário reajustar os parâmetros para a nova seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBAXqB_9Aj0f",
        "outputId": "db9f5ada-538e-4fd8-a5f8-c0cf62ae1ff9"
      },
      "source": [
        "cbc_treina_testa(dfTreino=df_treino_mf2, ts = 0.25, it=400, lr = 0.04, depth = 6, rs = 7)\n",
        "cbc_treina_testa(dfTreino=df_treino_mf2, ts = 0.25, it=400, lr = 0.04, depth = 6, rs = 210)\n",
        "cbc_treina_testa(dfTreino=df_treino_mf2, ts = 0.25, it=400, lr = 0.04, depth = 6, rs = 200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.25 it: 400 lr: 0.04 depth: 6 rs: 7 -> Score do Treino: %82.54\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 6 rs: 210 -> Score do Treino: %80.55\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 6 rs: 200 -> Score do Treino: %79.91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMQiqlnUCWyA"
      },
      "source": [
        "Com base na observação citada anteriormente, resolvi fazer diversas execuções do modelo, sem definir a \"seed\", testando diversas combinações de parâmetros, e armazenando os scores respectivos em um dicionário para análise posterior.   O objetivo era tentar encontrar alguma combinação de parâmetros em que houvesse pouca variação na acurácia para qualquer \"pedaço\" do conjunto de treino que fosse utilizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5q2-7QUDs6N"
      },
      "source": [
        "## 10. Loop para tentar identificar parâmetros que funcionariam bem para qualquer amostra do treino (DEMORADO - NÃO PRECISA EXECUTAR!!!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoNjvhyYD7Ae"
      },
      "source": [
        "### 10.1 Executa a função cbc_treina_testa() diversas vezes para cada diferente combinação dos parâmetros depth, learning_rate, iterations, armazenando os resultados em um dicionário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JAdJk84CQjQ",
        "outputId": "f5ab0099-a4af-4618-f1d2-b6da55dc568a"
      },
      "source": [
        "# Variáveis originais do loop (demora pra executar)\n",
        "#l_ts = [0.24, 0.25, 0.26, 0.28, 0.30] \n",
        "#l_it =  [80, 100, 200, 300, 400] \n",
        "#l_lr = [0.02, 0.03, 0.04, 0.05, 0.06] \n",
        "#l_depth = [2, 3, 4, 5, 6, 7, 8] \n",
        "#qtdeDeRepeticoes = 7\n",
        "\n",
        "#variáveis para uma demonstração mais rápida:\n",
        "l_ts = [ 0.25, 0.26] \n",
        "l_it =  [300, 400] \n",
        "l_lr = [0.03, 0.04, 0.05, 0.06] \n",
        "l_depth = [2, 3, 4, 5, 6, 7] \n",
        "qtdeDeRepeticoes = 3\n",
        "\n",
        "qtdeExecucoes = len(l_ts) * len(l_it) * len(l_lr) * len(l_depth) * qtdeDeRepeticoes\n",
        "resultado = {}\n",
        "\n",
        "for vez in range(1,qtdeDeRepeticoes+1):\n",
        "   resultado[vez] = {\"ts\":[], \"it\":[], \"lr\":[],\"depth\":[],\"score\":[]}\n",
        "   for ts in l_ts:\n",
        "       print(f'execução {vez}/ts {ts}...')\n",
        "       for it in l_it:\n",
        "           for lr in l_lr:\n",
        "               for depth in l_depth:\n",
        "                  res = cbc_treina_testa(dfTreino=df_treino_mf2, ts=ts, it=it, lr=lr, depth=depth,gerarArquivo=False, rs = None, mostrarFI=False) #não vai salvar o arquivo e nem mostrar as melhores features\n",
        "                  resultado[vez][\"ts\"].append(ts)\n",
        "                  resultado[vez][\"it\"].append(it)\n",
        "                  resultado[vez][\"lr\"].append(lr)\n",
        "                  resultado[vez][\"depth\"].append(depth)\n",
        "                  resultado[vez][\"score\"].append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execução 1/ts 0.25...\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 2 rs: None -> Score do Treino: %80.98\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 3 rs: None -> Score do Treino: %81.41\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 4 rs: None -> Score do Treino: %80.41\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 5 rs: None -> Score do Treino: %81.55\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 6 rs: None -> Score do Treino: %79.84\n",
            "ts: 0.25 it: 300 lr: 0.03 depth: 7 rs: None -> Score do Treino: %82.19\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 2 rs: None -> Score do Treino: %80.27\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 3 rs: None -> Score do Treino: %80.77\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 4 rs: None -> Score do Treino: %82.04\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 5 rs: None -> Score do Treino: %81.48\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 6 rs: None -> Score do Treino: %80.7\n",
            "ts: 0.25 it: 300 lr: 0.04 depth: 7 rs: None -> Score do Treino: %81.19\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 2 rs: None -> Score do Treino: %79.06\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 3 rs: None -> Score do Treino: %81.97\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 4 rs: None -> Score do Treino: %81.55\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 5 rs: None -> Score do Treino: %78.64\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 6 rs: None -> Score do Treino: %81.97\n",
            "ts: 0.25 it: 300 lr: 0.05 depth: 7 rs: None -> Score do Treino: %81.26\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 2 rs: None -> Score do Treino: %81.76\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 3 rs: None -> Score do Treino: %81.19\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 4 rs: None -> Score do Treino: %79.84\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 5 rs: None -> Score do Treino: %79.63\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 6 rs: None -> Score do Treino: %80.62\n",
            "ts: 0.25 it: 300 lr: 0.06 depth: 7 rs: None -> Score do Treino: %80.2\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 2 rs: None -> Score do Treino: %80.84\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 3 rs: None -> Score do Treino: %81.05\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 4 rs: None -> Score do Treino: %80.98\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 5 rs: None -> Score do Treino: %80.13\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 6 rs: None -> Score do Treino: %80.48\n",
            "ts: 0.25 it: 400 lr: 0.03 depth: 7 rs: None -> Score do Treino: %81.83\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: None -> Score do Treino: %79.84\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 3 rs: None -> Score do Treino: %80.77\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 4 rs: None -> Score do Treino: %80.2\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 5 rs: None -> Score do Treino: %80.77\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 6 rs: None -> Score do Treino: %80.41\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 7 rs: None -> Score do Treino: %80.98\n",
            "ts: 0.25 it: 400 lr: 0.05 depth: 2 rs: None -> Score do Treino: %81.41\n",
            "ts: 0.25 it: 400 lr: 0.05 depth: 3 rs: None -> Score do Treino: %80.34\n",
            "ts: 0.25 it: 400 lr: 0.05 depth: 4 rs: None -> Score do Treino: %80.55\n",
            "ts: 0.25 it: 400 lr: 0.05 depth: 5 rs: None -> Score do Treino: %80.98\n",
            "ts: 0.25 it: 400 lr: 0.05 depth: 6 rs: None -> Score do Treino: %80.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-88ffa5f77eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_depth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                   \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbc_treina_testa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTreino\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_treino_mf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgerarArquivo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmostrarFI\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#não vai salvar o arquivo e nem mostrar as melhores features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                   \u001b[0mresultado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvez\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"it\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-6-0eee66c45977>\u001b[0m in \u001b[0;36mcbc_treina_testa\u001b[1;34m(dfTreino, dfTeste, ts, it, lr, depth, rs, gerarArquivo, accMinGerarArquivo, mostrarFI)\u001b[0m\n\u001b[0;32m      6\u001b[0m    \u001b[0mX_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_teste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_teste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreditoras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[0mcatb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m    \u001b[0mcatb_tuned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[0mX_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m    \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatb_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m    \u001b[0macc_catb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_teste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4300\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4301\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4302\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1807\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1809\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1810\u001b[0m             )\n\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtQOxBh9KLoM"
      },
      "source": [
        "### 10.2 Transforma o dicionário gerado no passo anterior em um Dataframe e apresenta seus resultados organizados, permitindo verificar qual conjunto (ts,it, lr e depth) gerou boa média de nota e pequeno std.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_AgWHR9KUJ8"
      },
      "source": [
        "arrays = []\n",
        "for vez, v in resultado.items():\n",
        "    d = pd.DataFrame(v)\n",
        "    d[\"vez\"] = vez\n",
        "    arrays.append(d.copy())\n",
        "dfResultado = pd.concat(arrays,axis=0,sort=False)\n",
        "\n",
        "dfTotais = dfResultado.groupby(by=[\"ts\",\"it\",\"lr\",\"depth\"]).agg({\"score\":[\"min\",\"max\",\"mean\",\"std\"], \"vez\": [\"count\"]}).sort_values([(\"score\",\"mean\")],ascending=False)\n",
        "dfTotais.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NJOLoWWKo3F"
      },
      "source": [
        "### 10.3 Conclusão:\n",
        " * no exemplo acima, poderia dar preferência pelos parâmetros test_size=0.25, iterations=300, learning_rate = 0.05 e depth = 7. \n",
        " * Quando utilizei o dataframe de getMelhoresFeatures(), os parâmetros que encontrei foram ts = 0.26, it = 400, lr = 0.02 e depth = 3\n",
        " * Quando utilizei o dataframe de getMelhoresFeatures2(), os parâmetros que encontrei foram ts = 0.25, it = 400, lr = 0.04 e depth = 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2fr6r9hRlZE"
      },
      "source": [
        "## 11. executa o modelo diversas vezes (ex: 50X, 100x, etc.) com os \"melhores parâmetros\" encontrados, obtendo diversas acurácias diferentes (por causa da não especificação de um \"seed\" fixo para separação dos dados de treino e teste)\n",
        " \n",
        "#### obs: alterei a função para só gerar arquivos de submissão cuja nota do treino fosse superior ao valor mínio passado como parâmetro.   Depois disso, pegava os arquivos com as maiores notas e submetia no kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AKsn27iNCPB"
      },
      "source": [
        "# melhores parametros:\n",
        "ts = 0.25\n",
        "it = 400\n",
        "lr = 0.04\n",
        "depth = 2\n",
        "rs = None\n",
        "\n",
        "qtdeExecucoes = 50\n",
        "accMin_GerarArquivo = 80.5\n",
        "\n",
        "for vez in range(1,qtdeExecucoes+1):\n",
        "   res = cbc_treina_testa(dfTreino=df_treino_mf2, dfTeste=df_teste_mf2, ts=ts, it=it, lr=lr, rs = rs, depth=depth,gerarArquivo=True, accMinGerarArquivo = accMin_GerarArquivo, mostrarFI=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQSbknYKnqs"
      },
      "source": [
        "## 12. Salvar os melhores arquivos gerados anteriormente e submeter ao kaggle\n",
        "  * Conforme comentado anteriormente, nas execuções iniciais que fiz a maior nota que havia conseguido era 0.80397. \n",
        "  * Após conseguir repetir o mesmo resultado em 4 ocasiões diferentes, e por não ser possível utilizar a biblioteca de \"votting\" (pois não havia \"salvo\" os modelos que geraram as melhores notas, procedi da seguinte forma:\n",
        "  - fiz outro notebook, onde carreguei três arquivos csv´s gerados e que produziam a nota 0.80397.   \n",
        "  * concatenei os dataframes e comparei as três colunas de churn de cada linha, repetindo, e uma quarta coluna, o \"Churn\" que aparecia pelo menos duas veze na linha.  \n",
        "  * Salvei um novo arquivo \"csv\" com o resultado do \"churn\" que encontrei e submeti no kaggle, e foi quando a nota aumentou para 0.808xx\n",
        "  * Essa nota ficou liderando o ranking do kaggle sexta-feira (27).\n",
        "  * A partir de sexta-feira, ao refazer o notebook para apresentação, fiz diversos testes pra tentar descobrir uma maneira de deixar o notebook com \"seed\" fixo, e possibilitar a geração de arquivos que produzissem sempre as melhores notas obtidas no kaggle, sem ter que, necessariamente, gerar diversos arquivos aleatoriamente e contar com a \"sorte\".    \n",
        "  * Durante os testes, consegui definir seed´s fixos que produziram melhores resultados no kaggle, inclusive foi possível atingar pontuação maior que a anterior (0.80965) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF3JO8Tm1URv"
      },
      "source": [
        "## 13. Parâmetros para geração de arquivos com melhores notas no kaggle:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qqtLyq6vICA"
      },
      "source": [
        "### 13.1 Parâmetros para geração de arquivo com nota 0.80397"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "159J6OZ7vQAx",
        "outputId": "e4f35eaa-141d-4cdb-f97d-d2832e171bed"
      },
      "source": [
        "# melhores parametros:\n",
        "ts = 0.25\n",
        "it = 400\n",
        "lr = 0.04\n",
        "depth = 2\n",
        "l_rs = [15590, 68788]\n",
        "for rs in l_rs:\n",
        "    res = cbc_treina_testa(dfTreino=df_treino_mf2, dfTeste=df_teste_mf2, ts=ts, it=it, lr=lr, rs = rs, depth=depth,gerarArquivo=True, accMinGerarArquivo = 80, mostrarFI=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 15590 -> Score do Treino: %80.98\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs15590_sc8098.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 68788 -> Score do Treino: %81.55\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs68788_sc8155.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sy9EKqOrkwR"
      },
      "source": [
        "### 13.2 Parâmetros para geração de arquivo com nota 0.80539 no kaggle:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhDyYH-3rq6a",
        "outputId": "eb440b0b-6d89-472a-d11d-fe6334355b33"
      },
      "source": [
        "# melhores parametros:\n",
        "ts = 0.25\n",
        "it = 400\n",
        "lr = 0.04\n",
        "depth = 2\n",
        "l_rs = [24605, 55380, 23209, 45210]\n",
        "for rs in l_rs:\n",
        "    res = cbc_treina_testa(dfTreino=df_treino_mf2, dfTeste=df_teste_mf2, ts=ts, it=it, lr=lr, rs = rs, depth=depth,gerarArquivo=True, accMinGerarArquivo = 80, mostrarFI=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 24605 -> Score do Treino: %80.48\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs24605_sc8048.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 55380 -> Score do Treino: %81.55\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs55380_sc8155.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 23209 -> Score do Treino: %81.19\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs23209_sc8119.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 45210 -> Score do Treino: %80.98\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs45210_sc8098.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUznwxEEqdU1"
      },
      "source": [
        "### 13.3 Parâmetros para arquivo que gera nota 0.80681 no kaggle:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EbgRcuwqj7s",
        "outputId": "aa5de9a4-4fb9-4f19-b3a0-eb78d717e2a3"
      },
      "source": [
        "# melhores parametros:\n",
        "ts = 0.25\n",
        "it = 400\n",
        "lr = 0.04\n",
        "depth = 2\n",
        "l_rs = [31572, 38171, 31104]\n",
        "for rs in l_rs:\n",
        "    res = cbc_treina_testa(dfTreino=df_treino_mf2, dfTeste=df_teste_mf2, ts=ts, it=it, lr=lr, rs = rs, depth=depth,gerarArquivo=True, accMinGerarArquivo = 80, mostrarFI=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 31572 -> Score do Treino: %80.91\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31572_sc8091.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 38171 -> Score do Treino: %81.55\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs38171_sc8155.csv\n",
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 31104 -> Score do Treino: %81.41\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31104_sc8141.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUgLVbu60yKP"
      },
      "source": [
        "### 13.4 Parâmetros para geração de arquivo com nota 0.80965"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3EN_e3L09co",
        "outputId": "1cdd4c17-cbb5-4616-bceb-9c5aa269b367"
      },
      "source": [
        "# melhores parametros:\n",
        "ts = 0.25\n",
        "it = 400\n",
        "lr = 0.04\n",
        "depth = 2\n",
        "rs = 18353\n",
        "\n",
        "res = cbc_treina_testa(dfTreino=df_treino_mf2, dfTeste=df_teste_mf2, ts=ts, it=it, lr=lr, rs = rs, depth=depth,gerarArquivo=True, accMinGerarArquivo = 80, mostrarFI=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts: 0.25 it: 400 lr: 0.04 depth: 2 rs: 18353 -> Score do Treino: %80.34\n",
            "novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs18353_sc8034.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIB0OeN22Flk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFfaPCH74rvl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM5ZlWcP4sQo"
      },
      "source": [
        "## 14. Tentativa de melhorar a nota comparando os arquivos e reproduzindo o resultado que aparece mais vezes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWcIyKDrD14R"
      },
      "source": [
        "#### 14.1 função para comparar três diferentes arquivos e retornar um dataframe contendo o \"Churn\" que mais se repete: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3m65Kbv4S0D"
      },
      "source": [
        "#Função para carregar três diferentes arquivos e retornar o churn \n",
        "\n",
        "def melhor_de_tres(l_arquivos):\n",
        "    df_Final = None\n",
        "    vez = 0\n",
        "    for arquivo in l_arquivos:\n",
        "        df_atual = pd.read_csv(arquivo,  index_col=\"id\")\n",
        "        df_atual.rename(columns={\"Churn\": \"Churn_\"+str(vez)},inplace=True)\n",
        "        if (vez == 0):\n",
        "          df_Final = df_atual.copy()\n",
        "        else:\n",
        "          df_Final = pd.concat([df_Final, df_atual],axis=1)  \n",
        "        vez+=1   \n",
        "\n",
        "    df_Final[\"Churn_Soma\"] = df_Final.Churn_0 + df_Final.Churn_1 + df_Final.Churn_2 \n",
        "    df_Final[\"Churn\"] = np.where(df_Final.Churn_Soma >= 2,1,0) \n",
        "    df_Final.reset_index(inplace=True)\n",
        "    df_Final.rename(columns={\"index\":\"id\"})\n",
        "    return df_Final\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSnQa0RsEJ3x"
      },
      "source": [
        "### 14.2 - Comparação dos três arquivos que atingiram nota de 0.80681"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZkoG3_vAeZi",
        "outputId": "71b2a3d9-9993-42f1-9bfc-7dcfaf72b49c"
      },
      "source": [
        "# tres arquivos que atingiram 0.806\n",
        "l_arquivos = [\"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31104_sc8141.csv\",\n",
        "              \"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31572_sc8091.csv\",\n",
        "              \"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs38171_sc8155.csv\"]\n",
        "df_Final = melhor_de_tres(l_arquivos)\n",
        "df_Final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Churn_0</th>\n",
              "      <th>Churn_1</th>\n",
              "      <th>Churn_2</th>\n",
              "      <th>Churn_Soma</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1733</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5384</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6554</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>4897</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>6940</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>804</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1143</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1408</th>\n",
              "      <td>5773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1409 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  Churn_0  Churn_1  Churn_2  Churn_Soma  Churn\n",
              "0     5027        0        0        0           0      0\n",
              "1     1733        0        0        0           0      0\n",
              "2     5384        1        0        0           1      0\n",
              "3     6554        0        0        0           0      0\n",
              "4      364        0        0        0           0      0\n",
              "...    ...      ...      ...      ...         ...    ...\n",
              "1404  4897        0        0        0           0      0\n",
              "1405  6940        0        0        0           0      0\n",
              "1406   804        0        0        0           0      0\n",
              "1407  1143        1        1        1           3      1\n",
              "1408  5773        0        0        0           0      0\n",
              "\n",
              "[1409 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps2UQxZ3-5OG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7lszVbNBL7D"
      },
      "source": [
        "df_Final[[\"id\",\"Churn\"]].to_csv(\"teste_compara_3arquivos_nota_080681.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY-7cM8MEZYn"
      },
      "source": [
        "#### OBS: ao submeter o arquivo gerado, a nota no kaggle do novo arquivo tb foi 0.80681"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YJfUbDnFYkN"
      },
      "source": [
        "### 14.3 Comparação utilizando arquivo com nota 0.80965 e dois arquivos de nota 0.80681"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_qadH55Boq3"
      },
      "source": [
        "# arquivo de nota 0.809 e dois de 0.806\n",
        "l_arquivos = [\"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31104_sc8141.csv\",\n",
        "              \"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs31572_sc8091.csv\",\n",
        "              \"novo_submissao_kaggle_catb_fs_ts025.0_it400_lr0.04_depth2_rs18353_sc8034.csv\"]\n",
        "df_Final = melhor_de_tres(l_arquivos)\n",
        "df_Final[[\"id\",\"Churn\"]].to_csv(\"teste_compara_3arquivos_nota_0809_e0806.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbjW0XhHbGU"
      },
      "source": [
        "# RESULTADO: ao sumeter o novo arquivo, a nota subiu para **0.81107**!!!!!!"
      ]
    }
  ]
}